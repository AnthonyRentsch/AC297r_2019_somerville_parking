{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "sys.path.append('/notebook')\n",
    "\n",
    "from models import combined_cnn\n",
    "from loss import smooth_labels\n",
    "from metrics import sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe with filenames and labels\n",
    "sample = pd.read_csv('../labels/training_labels_updated_111219.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth labels\n",
    "sample['full_label'] = 'aerial_' + sample['AERIAL_Driveway'].astype(int).astype(str) + \\\n",
    "                       '_gsv_' + sample['GSV_Driveway'].astype(int).astype(str)\n",
    "sample['smooth_label'] = smooth_labels(sample['full_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label all unsures as 1s \n",
    "sample['temp_label'] = sample['final_label'].apply(lambda x: np.round(x))\n",
    "sample['temp_label'] = sample['temp_label'].astype('int').astype('str')\n",
    "sample['final_label'] =  sample['final_label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_labels(aerial, gsv):\n",
    "    labels = []\n",
    "    for aerial_, gsv_ in zip(aerial, gsv):\n",
    "        if aerial_ == 1 or gsv_ == 1:\n",
    "            labels.append(1)\n",
    "        elif aerial_ == 0 or gsv_ == 0:\n",
    "            labels.append(0)\n",
    "        elif aerial_ == 2 and gsv_ == 2:\n",
    "            labels.append(2)\n",
    "    return labels\n",
    "        \n",
    "sample['three_label'] = three_labels(sample['AERIAL_Driveway'], sample['GSV_Driveway'])\n",
    "sample['three_label'] = sample['three_label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak at data\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "aer_image_dim = (128, 128, 3) # (128, 128, 4)\n",
    "aerial_dir = '../data/training/aerial_images/'\n",
    "x_column = 'aerial_filename'\n",
    "y_column = 'three_label' #smooth_label, temp_label\n",
    "batch_size = 32\n",
    "color_mode = 'rgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "train_data, test_data = train_test_split(sample, test_size = 0.25, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print distribution of sets\n",
    "print('train')\n",
    "print(train_data[y_column].value_counts())\n",
    "print('test')\n",
    "print(test_data[y_column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalance\n",
    "rebalanced_train = pd.concat([train_data, \n",
    "                              train_data[train_data[y_column]=='0'],\n",
    "                              train_data[train_data[y_column]=='0'],\n",
    "                              train_data[train_data[y_column]=='0'],\n",
    "                              train_data[train_data[y_column]=='2'],\n",
    "                              train_data[train_data[y_column]=='2'],\n",
    "                              train_data[train_data[y_column]=='2'],\n",
    "                              train_data[train_data[y_column]=='2'],\n",
    "                              train_data[train_data[y_column]=='2'],\n",
    "                              train_data[train_data[y_column]=='2'],\n",
    "                              train_data[train_data[y_column]=='2'],\n",
    "                              train_data[train_data[y_column]=='2'],\n",
    "                              train_data[train_data[y_column]=='2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rebalanced train')\n",
    "print(rebalanced_train[y_column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and generator\n",
    "## train\n",
    "#drop_channel = lambda x: x[:,:,0:3]\n",
    "aerial_gen_obj = ImageDataGenerator(\n",
    "    #preprocessing_function=drop_channel,\n",
    "                                    horizontal_flip = True, vertical_flip = True, \n",
    "                                    width_shift_range = 0.1, height_shift_range = 0.1, \n",
    "                                    zoom_range = 0.1, rotation_range = 40)\n",
    "train_generator = aerial_gen_obj.flow_from_dataframe(rebalanced_train, directory = aerial_dir,  #train_data\n",
    "                                                x_col= x_column, y_col= y_column, \n",
    "                                                target_size=(aer_image_dim[0], aer_image_dim[1]), \n",
    "                                                color_mode=color_mode, class_mode='categorical', #class_mode='binary'\n",
    "                                                batch_size=batch_size, \n",
    "                                                shuffle=True, seed=100)\n",
    "\n",
    "## test\n",
    "test_generator = aerial_gen_obj.flow_from_dataframe(test_data, directory = aerial_dir, \n",
    "                                                x_col= x_column, y_col= y_column, \n",
    "                                                target_size=(aer_image_dim[0], aer_image_dim[1]), \n",
    "                                                color_mode=color_mode, class_mode='categorical', #class_mode='binary'\n",
    "                                                batch_size=batch_size, \n",
    "                                                shuffle=True, seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "def satellite_cnn(image_dim = aer_image_dim, n_classes=1):\n",
    "    \n",
    "    sat_input_img = layers.Input(shape=image_dim, name='aerial_image_input')\n",
    "    sat_cnn = layers.Conv2D(256, (3,3), activation = 'relu')(sat_input_img)\n",
    "    sat_cnn = layers.MaxPooling2D((2,2))(sat_cnn)\n",
    "    sat_cnn = layers.Conv2D(128, (3,3), activation = 'relu')(sat_cnn)\n",
    "    sat_cnn = layers.MaxPooling2D((2,2))(sat_cnn)\n",
    "    sat_cnn = layers.Conv2D(64, (3,3), activation = 'relu')(sat_cnn)\n",
    "    sat_cnn = layers.MaxPooling2D((2,2))(sat_cnn)\n",
    "    sat_cnn = layers.Conv2D(16, (3,3), activation = 'relu')(sat_cnn)\n",
    "    sat_cnn = layers.MaxPooling2D((2,2))(sat_cnn)\n",
    "    sat_cnn = layers.Conv2D(8, (3,3), activation = 'relu')(sat_cnn)\n",
    "    sat_cnn = layers.MaxPooling2D((2,2))(sat_cnn)\n",
    "    sat_flat = layers.Flatten()(sat_cnn)\n",
    "    sat_image_embedding = layers.Dense(300, activation='relu')(sat_flat)\n",
    "    \n",
    "    full_embedding = layers.Dense(200, activation='relu')(sat_image_embedding)\n",
    "    full_embedding = layers.Dropout(rate=0.5)(full_embedding)\n",
    "    full_embedding = layers.Dense(100, activation='relu')(full_embedding)\n",
    "    full_embedding = layers.Dropout(rate=0.3)(full_embedding)\n",
    "    full_embedding = layers.Dense(64, activation='relu')(full_embedding)\n",
    "    full_embedding = layers.Dropout(rate=0.1)(full_embedding)\n",
    "    output = layers.Dense(n_classes, activation='softmax')(full_embedding)\n",
    "    \n",
    "    model = models.Model(inputs=sat_input_img, outputs=output)\n",
    "    adam = optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy', sensitivity, specificity])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def satellite_cnn_transfer(image_dim = aer_image_dim, pre_trained = None, n_classes=1):\n",
    "    \n",
    "    if not pre_trained:\n",
    "        print('No model specified')\n",
    "        return \n",
    "        \n",
    "    sat_input_img = layers.Input(shape=image_dim, name='aerial_image_input')\n",
    "    \n",
    "    for layer in pre_trained.layers:\n",
    "        layer.trainable = False\n",
    "    pre_trained_embedding = pre_trained(sat_input_img)\n",
    "    pre_trained_embedding = layers.Flatten()(pre_trained_embedding)\n",
    "    \n",
    "    full_embedding = layers.Dense(300, activation='relu')(pre_trained_embedding)\n",
    "    full_embedding = layers.Dropout(rate=0.5)(full_embedding)\n",
    "    full_embedding = layers.Dense(200, activation='relu')(full_embedding)\n",
    "    full_embedding = layers.Dropout(rate=0.5)(full_embedding)\n",
    "    full_embedding = layers.Dense(100, activation='relu')(full_embedding)\n",
    "    full_embedding = layers.Dropout(rate=0.5)(full_embedding)\n",
    "    output = layers.Dense(n_classes, activation='softmax')(full_embedding)\n",
    "    \n",
    "    model = models.Model(inputs=sat_input_img, outputs=output)\n",
    "    #adam = optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    sgd = optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy', sensitivity, specificity])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transfer learning weights\n",
    "# inception_v3 = apps.inception_v3.InceptionV3(include_top=False, input_shape=aer_image_dim)\n",
    "dense_net = DenseNet201(include_top=False, input_shape=aer_image_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "# model = satellite_cnn(n_classes=3)\n",
    "model = satellite_cnn_transfer(pre_trained = dense_net, n_classes=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "epochs = 50\n",
    "val_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit_generator(generator=train_generator, \n",
    "                              validation_data=test_generator, \n",
    "                              validation_steps=val_steps, \n",
    "                              epochs=epochs,\n",
    "                              steps_per_epoch=np.ceil(train_data.shape[0]//batch_size),\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# model.save('../models/satellite_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model('../models/satellite_model.h5', \n",
    "#                    custom_objects={'sensitivity': sensitivity, 'specificity': specificity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_baseline_acc = rebalanced_train[y_column].value_counts().max()/rebalanced_train.shape[0]\n",
    "test_baseline_acc = test_data[y_column].value_counts().max()/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot performance\n",
    "fig, ax = plt.subplots(1, 4, figsize=(25,5))\n",
    "\n",
    "ax[0].plot(history.history['acc'], color='darkblue', label='train')\n",
    "ax[0].plot(history.history['val_acc'], color='darkred', label='val')\n",
    "ax[0].axhline(train_baseline_acc, color='darkblue', linestyle='dashed', label='train baseline')\n",
    "ax[0].axhline(test_baseline_acc, color='darkred', linestyle='dashed', label='val baseline')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Accuracy')\n",
    "\n",
    "ax[1].plot(history.history['sensitivity'], color='darkblue', label='train')\n",
    "ax[1].plot(history.history['val_sensitivity'], color='darkred', label='val')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Sensitivity')\n",
    "\n",
    "ax[2].plot(history.history['specificity'], color='darkblue', label='train')\n",
    "ax[2].plot(history.history['val_specificity'], color='darkred', label='val')\n",
    "ax[2].legend()\n",
    "ax[2].set_title('Specificity')\n",
    "\n",
    "ax[3].plot(history.history['loss'], color='darkblue', label='train')\n",
    "ax[3].plot(history.history['val_loss'], color='darkred', label='val')\n",
    "ax[3].legend()\n",
    "ax[3].set_title('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score training set and test set (even though it was used for validation)\n",
    "train_preds = model.predict_generator(train_generator)\n",
    "test_preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary prediction\n",
    "if len(train_preds.shape) == 1:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "\n",
    "    ax.hist(train_preds, color='darkblue', alpha=0.5, label='train scores')\n",
    "    ax.hist(test_preds, color='darkred', alpha=0.5, label='test scores')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_title('Distribution of model scores');\n",
    "    \n",
    "elif len(train_preds.shape) > 1:\n",
    "    label_map = {0: 'Predicted no driveway', 1: 'Preidcted yes driveway', 2: 'Predicted unsure'}\n",
    "    fig, ax = plt.subplots(1, train_preds.shape[1], sharex=True, figsize=(20,6))\n",
    "    \n",
    "    for i in range(train_preds.shape[1]):\n",
    "        ax[i].hist(train_preds[:,i], color='darkblue', alpha=0.5, label='train scores')\n",
    "        ax[i].hist(test_preds[:,i], color='darkred', alpha=0.5, label='test scores')\n",
    "        ax[i].legend()\n",
    "        ax[i].set_xlabel('Score')\n",
    "        ax[i].set_title(label_map[i])\n",
    "    fig.suptitle('Distribution of model scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharex=True, figsize=(20,6))\n",
    "for i in range(train_preds.shape[1]):\n",
    "    for lab in ['0', '1', '2']:\n",
    "        ax[i].hist(train_preds[rebalanced_train[y_column]==lab,i], alpha=0.3, density=True, label=lab)\n",
    "    ax[i].legend(title='True label');\n",
    "    ax[i].set_title('Predicted label ' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
