{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driveway prop mean: 0.18475750577367206, driveway prop sd: 0.01865093041001626\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "RANDOM_SEED = 1995\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "n_driveway = 353\n",
    "n_no_driveway = 80\n",
    "n_all = n_driveway + n_no_driveway\n",
    "prop_driveway_mean = n_no_driveway / n_all\n",
    "prop_driveway_se = np.sqrt(prop_driveway_mean*(1-prop_driveway_mean)/n_all)\n",
    "print(f\"driveway prop mean: {prop_driveway_mean}, driveway prop sd: {prop_driveway_se}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p(df_training, df_everything, bootstrap = False):\n",
    "    X_train, y_train, X_cal, y_cal, X_all = get_data(df_training, df_everything, bootstrap = bootstrap)\n",
    "\n",
    "    # train random forest\n",
    "    rf = RandomForestClassifier(bootstrap = False, max_depth=6, n_estimators = 256)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # validate\n",
    "    y_pred = rf.predict(X_cal)\n",
    "    \n",
    "    # train calibrator\n",
    "    pred_cal = rf.predict_proba(X_cal)[:,1].reshape(-1, 1)\n",
    "    calibrator = LogisticRegression(C = 1e30)\n",
    "    calibrator.fit(pred_cal, y_cal)\n",
    "    \n",
    "    calibration_curve(y_cal, pred_cal)\n",
    "    # calculate values \n",
    "    prob_true, prob_pred = calibration_curve(y_true=y_cal, \n",
    "        y_prob=calibrator.predict_proba(pred_cal)[:,1],\n",
    "        n_bins=20)\n",
    "\n",
    "    # make predictions\n",
    "    pred_all = rf.predict_proba(X_all)[:,1].reshape(-1, 1)\n",
    "    probs = calibrator.predict_proba(pred_all)[:,1]\n",
    "    return probs\n",
    "\n",
    "def get_data(df_train, df_everything, bootstrap = False):\n",
    "    df_train, df_cal = train_test_split(df_train, test_size = 0.2)\n",
    "\n",
    "    # upsample\n",
    "    df_train = upsample(df_train, 0.5)\n",
    "    if bootstrap:\n",
    "        prop_driveway = np.random.normal(prop_driveway_mean, prop_driveway_se)\n",
    "    else:\n",
    "        prop_driveway = prop_driveway_mean\n",
    "    df_cal = upsample(df_cal, prop_driveway)\n",
    "    \n",
    "    if bootstrap:\n",
    "        df_train = df_train.sample(frac = 1, replace = True)\n",
    "        print(df_train.has_parking.value_counts()[0]/len(df_train))\n",
    "        df_cal = df_cal.sample(frac = 1, replace = True)\n",
    "        print(df_cal.has_parking.value_counts()[0]/len(df_cal))\n",
    "\n",
    "    # prep clms\n",
    "    X_train = df_train.drop(['MBL', 'has_parking'], axis = 1)\n",
    "    y_train = df_train['has_parking']\n",
    "    \n",
    "    X_cal = df_cal.drop(['MBL', 'has_parking'], axis = 1)\n",
    "    y_cal = df_cal['has_parking']\n",
    "\n",
    "    X_all = df_everything.drop('MBL', axis = 1)\n",
    "    \n",
    "    # scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_cal = scaler.transform(X_cal)\n",
    "    X_all = scaler.transform(X_all)\n",
    "\n",
    "    return X_train, y_train, X_cal, y_cal, X_all\n",
    "\n",
    "\n",
    "def upsample(df, prop):\n",
    "    # upsample\n",
    "    n1 = sum(df.has_parking == 1)\n",
    "    n0 = sum(df.has_parking == 0)\n",
    "    extra = prop / (1 - prop) * n1\n",
    "\n",
    "    labels0 = df[df.has_parking == 0]\n",
    "    labels0_upsample = labels0.sample(int(extra - n0), replace = True)\n",
    "    labels_all_upsampled = pd.concat([df, labels0_upsample])\n",
    "    return labels_all_upsampled\n",
    "\n",
    "df_everything = pd.read_csv('../data/residence_addresses_googlestreetview_clean.csv', index_col = 0)\n",
    "df_training = pd.read_csv('../data/df_training.csv', index_col = 0)\n",
    "df_training = df_training[df_training.has_parking != 2]\n",
    "\n",
    "df_everything = df_everything.fillna(df_everything.mean())\n",
    "df_training = df_training.fillna(df_training.mean())\n",
    "\n",
    "prediction_df = pd.DataFrame()\n",
    "\n",
    "prediction_df['MBL'] = df_everything['MBL']\n",
    "prediction_df['p'] = get_p(df_training, df_everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.4992534129692833\n",
      "0.1529664045746962\n",
      "1\n",
      "0.5002134927412468\n",
      "0.19116632160110422\n",
      "2\n",
      "0.5072572038420491\n",
      "0.16995768688293372\n",
      "3\n",
      "0.5087178396768021\n",
      "0.175177304964539\n",
      "4\n",
      "0.4997873697639804\n",
      "0.16428571428571428\n",
      "5\n",
      "0.5015971039182283\n",
      "0.18840579710144928\n",
      "6\n",
      "0.5002135383301303\n",
      "0.18561643835616437\n",
      "7\n",
      "0.49914657563473436\n",
      "0.17707618393960192\n",
      "8\n",
      "0.49211759693225393\n",
      "0.21185286103542234\n",
      "9\n",
      "0.4945721583652618\n",
      "0.16147308781869688\n",
      "10\n",
      "0.49680715197956576\n",
      "0.1686746987951807\n",
      "11\n",
      "0.49904092071611256\n",
      "0.1873259052924791\n",
      "12\n",
      "0.5008508827908955\n",
      "0.17272727272727273\n",
      "13\n",
      "0.5045783645655877\n",
      "0.19548872180451127\n",
      "14\n",
      "0.5042616663115278\n",
      "0.1915041782729805\n",
      "15\n",
      "0.4968152866242038\n",
      "0.19916142557651992\n",
      "16\n",
      "0.49946604015378043\n",
      "0.2204515272244356\n",
      "17\n",
      "0.509263202725724\n",
      "0.1376281112737921\n",
      "18\n",
      "0.5011724578981027\n",
      "0.15555555555555556\n",
      "19\n",
      "0.5018073570061663\n",
      "0.19272976680384088\n",
      "20\n",
      "0.49755006391137624\n",
      "0.1886145404663923\n",
      "21\n",
      "0.5033041995310168\n",
      "0.1774193548387097\n",
      "22\n",
      "0.5029761904761905\n",
      "0.21492743607463718\n",
      "23\n",
      "0.4980785653287788\n",
      "0.23755806237558064\n",
      "24\n",
      "0.5013841567291312\n",
      "0.1987704918032787\n",
      "25\n",
      "0.5013865187713311\n",
      "0.16959887403237156\n",
      "26\n",
      "0.4974375400384369\n",
      "0.17364016736401675\n",
      "27\n",
      "0.5090348639455783\n",
      "0.1911049339819319\n",
      "28\n",
      "0.4988292890591741\n",
      "0.22018970189701897\n",
      "29\n",
      "0.49659429544487016\n",
      "0.1676056338028169\n",
      "30\n",
      "0.5077379690481238\n",
      "0.18035087719298246\n",
      "31\n",
      "0.4968044311887516\n",
      "0.19797297297297298\n",
      "32\n",
      "0.5054313099041533\n",
      "0.2101010101010101\n",
      "33\n",
      "0.49872068230277183\n",
      "0.1863013698630137\n",
      "34\n",
      "0.49337181954244175\n",
      "0.18614130434782608\n",
      "35\n",
      "0.5073529411764706\n",
      "0.15457875457875458\n",
      "36\n",
      "0.49829424307036246\n",
      "0.16468946266573622\n",
      "37\n",
      "0.5018115942028986\n",
      "0.16831683168316833\n",
      "38\n",
      "0.4935064935064935\n",
      "0.2157930565010211\n",
      "39\n",
      "0.5022407170294494\n",
      "0.1733983286908078\n",
      "40\n",
      "0.4930851063829787\n",
      "0.1871546961325967\n",
      "41\n",
      "0.5028778512044341\n",
      "0.1829608938547486\n",
      "42\n",
      "0.5009578544061303\n",
      "0.21580756013745706\n",
      "43\n",
      "0.5059726962457338\n",
      "0.16784203102961917\n",
      "44\n",
      "0.4937153813378781\n",
      "0.17192982456140352\n",
      "45\n",
      "0.5013832730368163\n",
      "0.1617961511047755\n",
      "46\n",
      "0.5023394300297745\n",
      "0.1824561403508772\n",
      "47\n",
      "0.49349680170575694\n",
      "0.2201467645096731\n",
      "48\n",
      "0.496697208608566\n",
      "0.17601683029453016\n",
      "49\n",
      "0.4957519116397621\n",
      "0.2059228650137741\n"
     ]
    }
   ],
   "source": [
    "bootstrap = 50\n",
    "\n",
    "for sample_num in range(bootstrap):\n",
    "    print(sample_num)\n",
    "    prediction_df['sample_' + str(sample_num)] = get_p(df_training, df_everything, bootstrap = True)\n",
    "\n",
    "sample_cols = [clm for clm in prediction_df.columns if 'sample' in clm]\n",
    "prediction_df['variance'] = prediction_df[sample_cols].var(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.75457768345348"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(\n",
    "    (prediction_df[sample_cols] * (1 - prediction_df[sample_cols])).mean(axis = 1).sum() + prediction_df[sample_cols].var(axis = 1).sum()\n",
    ") * 1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.5010665529010239\n",
      "0.21002710027100271\n",
      "1\n",
      "0.4928556195350821\n",
      "0.17422096317280453\n",
      "2\n",
      "0.5002130379207499\n",
      "0.17464788732394365\n",
      "3\n",
      "0.5014899957428693\n",
      "0.16341287057122197\n",
      "4\n",
      "0.5039428815004262\n",
      "0.19710544452102\n",
      "5\n",
      "0.4981911044903171\n",
      "0.16678346180798878\n",
      "6\n",
      "0.49701619778346123\n",
      "0.16563997262149213\n",
      "7\n",
      "0.5001065643648764\n",
      "0.16502808988764045\n",
      "8\n",
      "0.5007472245943638\n",
      "0.19820441988950277\n",
      "9\n",
      "0.4973358908780904\n",
      "0.2045769764216366\n"
     ]
    }
   ],
   "source": [
    "point_est = prediction_df.p.sum()\n",
    "se = np.sqrt((prediction_df.p * (1 - prediction_df.p) + prediction_df.variance).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of driveways: 10119.965090707094 +/- 71.34345277062235\n"
     ]
    }
   ],
   "source": [
    "print(f\"# of driveways: {point_est} +/- {1.96 * se}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_training.drop(['MBL','has_parking'], axis = 1).columns\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "feature_imp = dict(zip(features, importances))\n",
    "\n",
    "import operator\n",
    "sorted(feature_imp.items(), key=operator.itemgetter(1), reverse = True)[:20]\n",
    "pd.DataFrame(sorted(feature_imp.items(), key=operator.itemgetter(1), reverse = True)[:20]).to_csv('../data/feature_imp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "somerville",
   "language": "python",
   "name": "somerville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
