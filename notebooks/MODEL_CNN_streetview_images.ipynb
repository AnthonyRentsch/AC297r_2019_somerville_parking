{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package imports\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "sys.path.append('../')\n",
    "from src.models import street_view_cnn\n",
    "sys.path.append('/notebook')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam1= pd.read_csv('../labels/training_labels_updated_111219.csv')\n",
    "sam2 = pd.read_csv('../labels/additional_training_labels_120319.csv')\n",
    "sample=pd.concat([sam1, sam2], axis = 0)\n",
    "assert sample.shape[0] == sam1.shape[0] + sam2.shape[0]\n",
    "\n",
    "# option to include additional labels - trained with these on a GPU\n",
    "# sample3 = pd.read_csv('../labels/new6000_training_labels_aerial.csv', index_col='Unnamed: 0') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the top\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the street view model - train on steet view driveway labels\n",
    "sample['GSV_Driveway'] = sample['GSV_Driveway'].astype('int').astype('str')\n",
    "sample.loc[sample['GSV_Driveway'] == '2', 'GSV_Driveway'] = '0' #<- this is to make sure we only have two labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split into train and validation (calling it test here)\n",
    "train_data, test_data = train_test_split(sample, test_size = 0.2, random_state = 100)\n",
    "y_column = 'GSV_Driveway'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For street view driveways, we have three labelled classes (0: no driveway; 1: driveway; 2: unsure)  \n",
    "We tried two variants of models:\n",
    "1. Learn these three classes\n",
    "2. Set 0 and 2 to be the same class - we want to be able to predict the driveways accurately\n",
    "\n",
    "This notebook shows option 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minority class oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_data.groupby(y_column).aggregate({'MBL':len}))\n",
    "display(test_data.groupby(y_column).aggregate({'MBL':len}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificially oversample the minority class - TRAINING\n",
    "zero_class = train_data[train_data[y_column] == '0']\n",
    "one_class = train_data[train_data[y_column] == '1']\n",
    "\n",
    "train_data = one_class.append(zero_class)\n",
    "for i in range(one_class.shape[0]//zero_class.shape[0]-1):\n",
    "    train_data = train_data.append(zero_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificially oversample the minority class - TEST\n",
    "zero_class = test_data[test_data[y_column] == '0']\n",
    "one_class = test_data[test_data[y_column] == '1']\n",
    "\n",
    "test_data = one_class.append(zero_class)\n",
    "for i in range(one_class.shape[0]//zero_class.shape[0]-1):\n",
    "    test_data = test_data.append(zero_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train_data.groupby(y_column).aggregate({'MBL':len}))\n",
    "# display(test_data.groupby(y_column).aggregate({'MBL':len}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input params\n",
    "sv_image_dim = (128, 128, 3)\n",
    "lr = 1e-4\n",
    "batch_size = 256\n",
    "val_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer - adam \n",
    "optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "# define learning rate decay method - two options\n",
    "# lr_decay = tensorflow.keras.callbacks.LearningRateScheduler(schedule=lambda epoch: lr * (0.9 ** epoch)) \n",
    "lr_decay = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                        factor=0.1, \n",
    "                                                        patience=2, \n",
    "                                                        verbose=True, \n",
    "                                                        mode='auto',\n",
    "                                                        min_delta=0.0001, \n",
    "                                                        cooldown=1, \n",
    "                                                        min_lr=1e-9)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                               min_delta=0.001,\n",
    "                                               patience=5, \n",
    "                                               verbose=True,\n",
    "                                               mode='auto', \n",
    "                                               baseline=None, \n",
    "                                               restore_best_weights=True)\n",
    "\n",
    "# define loss - cat xentropy\n",
    "loss = keras.losses.BinaryCrossentropy(label_smoothing=0.1) #smoothed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pretrained model \n",
    "pretrained_model = keras.applications.resnet50.ResNet50(include_top=False, input_shape=sv_image_dim)\n",
    "print('number of layers in pretrained model: ', len(pretrained_model.layers))\n",
    "\n",
    "# I tried unfreezing none to some - more fine tuning required here but not sure it makes much of a diff atm\n",
    "for layer in pretrained_model.layers[:-80]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model using function from models.py\n",
    "model = street_view_cnn(pretrained_model, \n",
    "                        image_dim = sv_image_dim, \n",
    "                        optimizer = optimizer,\n",
    "                        loss = loss,\n",
    "                        n_classes=2,\n",
    "                        activation = 'sigmoid',\n",
    "                        metrics=['accuracy'], \n",
    "                       )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs to generator\n",
    "image_dir = '../data/training/sv_images/'\n",
    "x_column = 'gsv_filename'\n",
    "color_mode = 'rgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_obj = ImageDataGenerator(rescale=1.0/255.0, \n",
    "                             zoom_range = 0.2 #adding zoom range as some images are super zoomed in/out\n",
    "                            ) \n",
    "\n",
    "## train\n",
    "train_generator = gen_obj.flow_from_dataframe(train_data, \n",
    "                                            directory = image_dir, \n",
    "                                            x_col= x_column, \n",
    "                                            y_col= y_column, \n",
    "                                            target_size=(sv_image_dim[0], sv_image_dim[1]), \n",
    "                                            color_mode=color_mode, \n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True,\n",
    "                                            seed=10)\n",
    "\n",
    "## test (i.e. validation)\n",
    "test_gen_obj = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_generator = test_gen_obj.flow_from_dataframe(test_data, \n",
    "                                            directory = image_dir, \n",
    "                                            x_col= x_column, \n",
    "                                            y_col= y_column, \n",
    "                                            target_size=(sv_image_dim[0], sv_image_dim[1]), \n",
    "                                            color_mode=color_mode, \n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=val_batch_size, \n",
    "                                            shuffle=True,\n",
    "                                            seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check thaat the generator works\n",
    "store = next(train_generator)\n",
    "plt.imshow(store[0][2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "epochs = 30\n",
    "val_steps = test_data.shape[0]//val_batch_size\n",
    "\n",
    "# train model\n",
    "history = model.fit_generator(generator=train_generator, \n",
    "                              validation_data=test_generator, \n",
    "                              validation_steps=val_steps,\n",
    "                              epochs=epochs,\n",
    "                              steps_per_epoch=np.ceil(train_data.shape[0]//batch_size),\n",
    "                              verbose=1,\n",
    "                              callbacks=[lr_decay]\n",
    "#                               callbacks=[lr_decay, early_stopping]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train model\n",
    "history1 = model.fit_generator(generator=train_generator, \n",
    "                              validation_data=test_generator, \n",
    "                              validation_steps=val_steps,\n",
    "                              epochs=epochs,\n",
    "                              steps_per_epoch=np.ceil(train_data.shape[0]//batch_size),\n",
    "                              verbose=1,\n",
    "                              callbacks=[lr_decay, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = {}\n",
    "for key in history.history.keys():\n",
    "    hist[key] = history.history[key] + history1.history[key] #+ history2.history[key]  + history3.history[key] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist['acc'], label = 'acc')\n",
    "plt.plot(hist['val_acc'], label = 'val acc')\n",
    "plt.title('Accuracy by epoch', fontsize = 20)\n",
    "plt.xticks(np.arange(0,len(hist['acc'])), rotation = 90);plt.xlabel('epoch')\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist['loss'], label = 'Training Loss')\n",
    "plt.plot(hist['val_loss'], label = 'Val Loss')\n",
    "plt.title('Loss by epoch', fontsize = 20)\n",
    "plt.xticks(np.arange(0,len(hist['acc'])), rotation = 90); plt.xlabel('epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN ACCURACY\n",
    "gen_obj = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_generator = gen_obj.flow_from_dataframe(train_data, \n",
    "                                            directory = image_dir,  \n",
    "                                            x_col= x_column, \n",
    "                                            y_col= y_column, \n",
    "                                            target_size=(sv_image_dim[0], sv_image_dim[1]), \n",
    "                                            color_mode=color_mode, \n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=train_data.shape[0], \n",
    "                                            shuffle=False, \n",
    "                                            seed=10)\n",
    "\n",
    "train_preds = model.predict_generator(train_generator, steps = 1)\n",
    "train_data['predicted_label'] = np.argmax(train_preds, axis = 1)\n",
    "sum(train_data[y_column].astype('int') == train_data.predicted_label.astype('int'))/len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST ACCURACY\n",
    "test_gen_obj = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_generator = test_gen_obj.flow_from_dataframe(test_data, \n",
    "                                            directory = image_dir, \n",
    "                                            x_col= x_column, \n",
    "                                            y_col= y_column, \n",
    "                                            target_size=(sv_image_dim[0], sv_image_dim[1]), \n",
    "                                            color_mode=color_mode, \n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=test_data.shape[0], \n",
    "                                            shuffle=False,\n",
    "                                            seed=10)\n",
    "\n",
    "test_preds = model.predict_generator(test_generator, steps = 1)\n",
    "test_data['predicted_label'] = np.argmax(test_preds, axis = 1)\n",
    "sum(test_data.three_class_label.astype('int') == test_data.predicted_label.astype('int'))/len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of results - 3 class model\n",
    "\n",
    "Unfortunately, due to saving issues, we did not have the 2 class model. Instead, we visualize what happened while training the three class model. The model is having a hard time differentiating bw the three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary prediction\n",
    "if len(train_preds.shape) == 1:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "\n",
    "    ax.hist(train_preds, color='darkblue', alpha=0.5, label='train scores')\n",
    "    ax.hist(test_preds, color='darkred', alpha=0.5, label='test scores')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_title('Distribution of model scores');\n",
    "    \n",
    "elif len(train_preds.shape) > 1:\n",
    "    label_map = {0: 'Predicted no driveway', 1: 'Predicted yes driveway', 2: 'Predicted unsure'}\n",
    "    fig, ax = plt.subplots(1, train_preds.shape[1], sharex=True, figsize=(20,6))\n",
    "    \n",
    "    for i in range(train_preds.shape[1]):\n",
    "        ax[i].hist(train_preds[:,i], color='darkblue', alpha=0.5, label='train scores')\n",
    "        ax[i].hist(test_preds[:,i], color='darkred', alpha=0.5, label='test scores')\n",
    "        ax[i].legend()\n",
    "        ax[i].set_xlabel('Score')\n",
    "        ax[i].set_title(label_map[i])\n",
    "    fig.suptitle('Distribution of model scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_data['three_class_label'] == train_data['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharex=True, figsize=(20,6))\n",
    "for i in range(train_preds.shape[1]):\n",
    "    for lab in ['0','1','2']:\n",
    "        ax[i].hist(train_preds[train_data[y_column]==lab,i], alpha=0.3, density=True, label=lab)\n",
    "    ax[i].legend(title='True label');\n",
    "    ax[i].set_title('Predicted label ' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/sv_transfer_model_learningratescheduler_es.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('../models/sv_transfer_model_weights_learningratescheduler_es.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = load_model('../models/sv_transfer_model_learningratescheduler.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
